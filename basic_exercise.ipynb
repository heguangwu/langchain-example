{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `langchain`基础\n",
    "\n",
    "`langchain`基础包括：\n",
    "\n",
    "- 提示词模板\n",
    "- 输出解析器\n",
    "- 链式调用\n",
    "\n",
    "\n",
    "\n",
    "## 提示词模板\n",
    "\n",
    "提示词角色有三种：\n",
    "\n",
    "- `system`: 系统角色\n",
    "- `human`: 用户角色，在OpenAI里面是 `user`\n",
    "- `assistant`: AI角色\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个省钱小能手，尽最大努力帮用户省钱。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我想买一个MacBook Pro', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', '你是一个省钱小能手，尽最大努力帮用户省钱。'),\n",
    "        ('human', '我想买一个{product}')\n",
    "    ]\n",
    ")\n",
    "result = prompt_template.invoke({'product': 'MacBook Pro'})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`MessagesPlaceholder`占位符，可以将历史消息或多条消息放入上下文中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个总结小助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的名字叫李明', additional_kwargs={}, response_metadata={}), HumanMessage(content='我今年29岁', additional_kwargs={}, response_metadata={}), HumanMessage(content='我正在学习AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='请总结一下我的信息', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '你是一个总结小助手'),\n",
    "    MessagesPlaceholder('history_messages'),\n",
    "    #  上述MessagesPlaceholder等同于：('placeholder', 'history_messages')\n",
    "    ('human', '{message}')\n",
    "])\n",
    "\n",
    "history_message = [HumanMessage('我的名字叫李明'), HumanMessage('我今年29岁'), HumanMessage('我正在学习AI')]\n",
    "prompt_template.invoke({'history_messages': history_message, 'message': '请总结一下我的信息'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出解析器\n",
    "\n",
    "作用是对输出数据进行格式化处理，输出解析器也可以调用大模型对消息进行进一步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: content='<think>\\n\\n</think>\\n\\nI want to eat noodles at noon.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 18, 'total_tokens': 31, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-r1:14b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-a1359169-a5be-4f71-8f28-793493066ea6-0' usage_metadata={'input_tokens': 18, 'output_tokens': 13, 'total_tokens': 31, 'input_token_details': {}, 'output_token_details': {}}\n",
      "格式化： <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "I want to eat noodles at noon.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 这里调用的是 ollama 本地模型\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-r1:14b',\n",
    "    base_url='http://192.168.1.188:11434/v1',\n",
    "    api_key='your_api_key'\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='你是一个翻译高手'),\n",
    "    HumanMessage(content='请将中文翻译为英文'),\n",
    "    HumanMessage(content='中午我想吃面条'),\n",
    "]\n",
    "\n",
    "# 字符串格式化\n",
    "parser = StrOutputParser()\n",
    "result = model.invoke(messages)\n",
    "print('AI:', result)\n",
    "response = parser.invoke(result)\n",
    "print('格式化：', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 链式调用\n",
    "\n",
    "类似`Linux`的管道操作，将多个执行器串联一起输出最终结果。\n",
    "上述的代码使用链式调用可以写成如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: <think>\n",
      "好吧，用户让我总结他的信息。他提供了自己的名字、年龄、正在学习的内容以及兴趣爱好。我觉得我需要把这些信息组织得清晰一些。\n",
      "\n",
      "首先，他会叫李明，29岁。然后在学习AI，这可能和职业发展有关。喜欢摄影说明他有艺术方面的兴趣。结合起来，这个总结可以突出他的学习领域和他的个人爱好之间的平衡。\n",
      "\n",
      "或许我可以分成几个点：基本信息、当前学习、兴趣爱好。这样结构更清晰，也便于阅读。同时，用简洁的语言来表达每个部分，避免冗长。\n",
      "\n",
      "需要注意的是，不使用任何markdown格式，保持自然的口语化中文。还要确保内容全面，涵盖所有提供的信息，但不过于详细。\n",
      "\n",
      "最后，检查一下是否有遗漏的信息或者有没有更合适的表达方式。确保总结既准确又易于理解。\n",
      "</think>\n",
      "\n",
      "你的信息可以总结如下：\n",
      "\n",
      "- **的名字：李明  \n",
      "- **年龄**：29岁  \n",
      "- **正在学习**：AI  \n",
      "- **兴趣爱好**：摄影  \n",
      "\n",
      "希望这样的总结对你有帮助！如果有其他需求，请随时告诉我。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 这里调用的是 ollama 本地模型\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-r1:14b',\n",
    "    base_url='http://192.168.1.188:11434/v1',\n",
    "    api_key='your_api_key'\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '你是一个总结小助手。'),\n",
    "    MessagesPlaceholder(variable_name='history_messages'),\n",
    "    ('human', '{input_message}')\n",
    "])\n",
    "\n",
    "history_message = [\n",
    "    ('human','我的名字叫李明'),\n",
    "    ('human','我今年29岁'),\n",
    "    ('human','我正在学习AI'),\n",
    "    ('human','我喜欢摄影')\n",
    "]\n",
    "# 链式调用等同于：prompt_template.invoke && model.invoke && StrOutputParser().invoke\n",
    "chain =  prompt_template | model | StrOutputParser()\n",
    "result = chain.invoke(input={'input_message': '请总结一下我的信息', 'history_messages': history_message})\n",
    "print('AI:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面简单介绍一下通过`SequentialChain`将多个模型串联起来：\n",
    "\n",
    "- 通过`input_variables`指定第一个链的输入的`key`\n",
    "- 通过`output_variables`指定每一个链的输出`key`\n",
    "- 将上一个模型`output key` 作为下一个模型`input key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[李明]\n",
      "\n",
      "[联系信息]\n",
      "手机：138xxxx5678\n",
      "电子邮箱：liming@example.com\n",
      "LinkedIn：linkedin.com/in/liming\n",
      "居住地：长沙市\n",
      "\n",
      "[个人简介]\n",
      "热情、有责任心的计算机科学与技术专业毕业生，拥有扎实的编程基础和良好的逻辑思维能力。对人工智能领域充满兴趣，并持续学习相关技能。擅长团队协作，具备良好的沟通能力和问题解决能力。渴望在技术领域发挥潜力，为团队贡献自己的力量。\n",
      "\n",
      "[教育背景]\n",
      "- 湖南大学\n",
      "  - 计算机科学与技术专业\n",
      "  - 学士学位\n",
      "  - 2018年9月 - 2022年6月\n",
      "\n",
      "[专业技能]\n",
      "- 熟练掌握Java、Python、C++等编程语言。\n",
      "- 熟悉Linux操作系统和常用命令。\n",
      "- 熟练使用MySQL、Oracle等数据库管理系统。\n",
      "- 熟悉HTML、CSS、JavaScript等前端技术。\n",
      "- 了解数据结构与算法设计。\n",
      "- 在人工智能领域，具备机器学习、深度学习的基础知识，熟悉TensorFlow和PyTorch等框架。\n",
      "\n",
      "[项目经验]\n",
      "- **智能图像识别系统**（2021年）\n",
      "  - 参与开发一款基于深度学习的图像识别系统，用于自动识别和分类图像。\n",
      "  - 负责模型训练和优化，提高了识别准确率。\n",
      "  - 使用TensorFlow框架实现，参与系统部署和测试。\n",
      "\n",
      "- **在线教育平台**（2020年）\n",
      "  - 参与开发一个在线教育平台，负责用户注册、登录模块的开发。\n",
      "  - 使用Java和Spring框架进行后端开发，实现用户认证和权限管理。\n",
      "  - 与前端团队协作，确保系统界面友好，用户体验良好。\n",
      "\n",
      "[实习经历]\n",
      "- **XX科技有限公司**\n",
      "  - 软件开发实习生\n",
      "  - 2019年7月 - 2019年9月\n",
      "  - 参与公司内部管理系统的开发，负责部分模块的设计与实现。\n",
      "  - 协助团队进行代码审查，提高代码质量。\n",
      "\n",
      "[兴趣爱好]\n",
      "- 摄影：热爱用镜头捕捉生活中的美好瞬间。\n",
      "- 阅读：广泛阅读科技、历史、文学等各类书籍，不断丰富知识储备。\n",
      "\n",
      "[证书]\n",
      "- 计算机技术与软件专业技术资格（水平）考试——软件设计师\n",
      "- 英语六级证书\n",
      "\n",
      "[自我评价]\n",
      "- 学习能力强，对新知识接受速度快。\n",
      "- 工作认真负责，具有良好的团队合作精神。\n",
      "- 乐观积极，面对挑战能够保持冷静，寻找解决问题的方法。\n",
      "\n",
      "[求职意向]\n",
      "- 求职岗位：人工智能工程师/软件开发工程师\n",
      "- 求职类型：全职\n",
      "- 工作地点：长沙市\n",
      "\n",
      "[附加信息]\n",
      "- 简历更新日期：2023年4月\n",
      "\n",
      "请注意，以上简历内容为示例，具体信息需要根据实际情况进行修改和补充。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# 加载智谱开放平台模型的相关参数\n",
    "load_dotenv()\n",
    "# 这里调用的是 ollama 本地模型\n",
    "llm1 = ChatOpenAI(\n",
    "    model='deepseek-r1:14b',\n",
    "    base_url='http://192.168.1.188:11434/v1',\n",
    "    api_key='your_api_key'\n",
    ")\n",
    "# 调用智谱开放平台模型，在.env中配置 OPENAI_API_KEY 和 OPENAI_BASE_URL\n",
    "llm2 = ChatOpenAI (model='glm-4-flash')\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_messages([\n",
    "    ('system', '你是一个总结小助手。'),\n",
    "    ('human','我的名字叫李明'),\n",
    "    ('human','我今年29岁'),\n",
    "    ('human','2022年毕业于湖南大学计算机科学与技术专业'),\n",
    "    ('human','我正在学习AI'),\n",
    "    ('human','我喜欢摄影'),\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1, output_key=\"summary\")\n",
    "\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    ('system', '你是一个简历小助手。'),\n",
    "    ('human', '{summary}'),\n",
    "    ('human', '帮我写一个详细的求职简历')\n",
    "])\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2, output_key=\"final_answer\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"input\"],  # 初始输入变量\n",
    "    output_variables=[\"summary\", \"final_answer\"],  # 最终输出变量\n",
    "    verbose=True\n",
    ")\n",
    "result = overall_chain.invoke('请总结一下我的信息')\n",
    "print(result[\"final_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
